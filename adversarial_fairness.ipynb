{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a20bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4708242",
   "metadata": {},
   "source": [
    "## Fairness Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a900958c",
   "metadata": {},
   "source": [
    "### 1. Equal Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818fefb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: \n",
    "    y_truth: ground truth\n",
    "    y_pred: predictions\n",
    "    label: name of the ground truth label (e.g., openness)\n",
    "    sen_att: sensitive attribute (list of values)\n",
    "    sen_type: name of the sensitive attribute of insterest (e.g., gender, ethnicity)\n",
    "    verbose: 1: show plots and Intermediate steps; 0: don't print any Intermediate steps\n",
    "Output: \n",
    "    dis_mae: dictionary of the MAE distance between group pairs. \n",
    "             key: names of demographic groups; value: MAE distance\n",
    "\"\"\"\n",
    "def acc_compare(y_truth, y_pred, label, sen_att, sen_type, verbose=True):\n",
    "    genders={1:'Male',2:'Female'}\n",
    "    races={1:'Asian',2:'Caucasian',3:'African-American'}\n",
    "    \n",
    "    print(\"=======%s=======\"%label)\n",
    "    if(verbose == True):\n",
    "        print (\"R2 on Test: %f\"%r2_score(y_truth,y_pred))\n",
    "        print (\"Corr. on Test: \",pearsonr(y_truth,y_pred))\n",
    "        print (\"MSE on Test: %f\"%mean_squared_error(y_truth,y_pred))\n",
    "        print (\"MAE on Test: %f\"%mean_absolute_error(y_truth,y_pred))\n",
    "        plt.figure()\n",
    "        plt.scatter(y_truth,y_pred, c=\"k\",alpha=0.4)\n",
    "        plt.xlabel('Ground Truth')\n",
    "        plt.ylabel('Prediction')\n",
    "        plt.title('Test: %s'%label)\n",
    "        plt.show()\n",
    "    \n",
    "    #get the sensitive attribute info\n",
    "    colors=['b','r','g']\n",
    "    groups=list(set(sen_att))\n",
    "    if(sen_type=='Gender'):\n",
    "        g_names=genders\n",
    "    elif(sen_type=='Ethnicity'):\n",
    "        g_names=races\n",
    "        \n",
    "    errs=[]\n",
    "    maes=[]\n",
    "    for g in groups:\n",
    "        y_t_g=[y_truth[i] for i in range(len(y_truth)) if sen_att[i]==g]\n",
    "        y_p_g=[y_pred[i] for i in range(len(y_pred)) if sen_att[i]==g]\n",
    "        if(verbose == True):\n",
    "            print(\"----%s----\"%g_names[g])        \n",
    "            print (\"R2 on Test: %f\"%r2_score(y_t_g,y_p_g))\n",
    "            print (\"Corr. on Test: \",pearsonr(y_t_g,y_p_g))\n",
    "            print (\"MSE on Test: %f\"%mean_squared_error(y_t_g,y_p_g))\n",
    "            print (\"MAE on Test: %f\"%mean_absolute_error(y_t_g,y_p_g))\n",
    "            plt.figure()\n",
    "            plt.scatter(y_t_g,y_p_g, c=colors[g-1],alpha=0.4)\n",
    "            plt.xlabel('Ground Truth')\n",
    "            plt.ylabel('Prediction')\n",
    "            plt.title('Test: %s'%label)\n",
    "            plt.show()\n",
    "        errs.append([y_p_g[i]-y_t_g[i] for i in range(len(y_p_g))])\n",
    "        maes.append(mean_absolute_error(y_t_g,y_p_g))\n",
    "\n",
    "    if(verbose == True):\n",
    "        for i in range(len(errs)):\n",
    "            sns.distplot(errs[i],color=colors[i])\n",
    "        plt.title('Error dist: %s'%label)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"T-test\")\n",
    "        for i in range(len(errs)):\n",
    "            g1=groups[i]\n",
    "            for j in range(i+1,len(errs)):\n",
    "                g2=groups[j]\n",
    "                print(\"%s-%s: \"%(g_names[g1],g_names[g2]),ttest_ind(errs[i],errs[j]))\n",
    "\n",
    "    print(\"MAE differences\")\n",
    "    dis_mae={}\n",
    "    for i in range(len(maes)):\n",
    "        g1=groups[i]\n",
    "        for j in range(i+1,len(maes)):\n",
    "            g2=groups[j]\n",
    "            t,p=ttest_ind(errs[i],errs[j])\n",
    "            print(\"%s-%s: \"%(g_names[g1],g_names[g2]),maes[i]-maes[j])\n",
    "            if(p<0.05):\n",
    "                print(\"Significant! \",p)\n",
    "            dis_mae.setdefault((g_names[g1],g_names[g2]), maes[i]-maes[j])\n",
    "    \n",
    "    return dis_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea0997c",
   "metadata": {},
   "source": [
    "### 2. Mutual Information (MI) Gain\n",
    "Compare the MI increase in predictions and ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f2f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_mi(y_truth, y_pred, label, sen_att, sen_type):\n",
    "    y_truth=np.array(y_truth).reshape(-1, 1)\n",
    "    y_pred=np.array(y_pred).reshape(-1, 1)\n",
    "    return mutual_info_classif(y_pred, sen_att, n_neighbors=5, random_state=0)[0]- mutual_info_classif(y_truth, sen_att, n_neighbors=5, random_state=0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d70e2e9",
   "metadata": {},
   "source": [
    "## Adversarial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055fd364",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, disc_n):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(feat_ed-feat_st,40, bias=True)\n",
    "        # self.fc1 = nn.Linear(81061, 40, bias=True)\n",
    "        self.fc2 = nn.Linear(40, 20)\n",
    "        self.discr_linear = nn.Linear(20, disc_n, bias=True)\n",
    "        self.pred_linear =  nn.Linear(20,1, bias = True)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #filter\n",
    "        h = self.fc1(x)\n",
    "        h = F.relu(h)\n",
    "        h = self.fc2(h)\n",
    "        filtered = F.relu(h)    \n",
    "\n",
    "        ## discriminator\n",
    "        discr = self.discr_linear(filtered)\n",
    "\n",
    "        ## pred\n",
    "        pred = self.pred_linear(filtered).squeeze()\n",
    "\n",
    "        return discr, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccaf6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## statistics of FI dataset\n",
    "feat_dim = 81061\n",
    "if modality_id == 0:\n",
    "    feat_st = 0\n",
    "    feat_ed = 70592\n",
    "elif modality_id == 1:\n",
    "    feat_st = 70592\n",
    "    feat_ed = feat_dim\n",
    "    \n",
    "features = torch.from_numpy(d[:,feat_st:feat_ed]).float()\n",
    "if disc_type  == 'Ethnicity':\n",
    "    disc_n = 3\n",
    "    class_labels = torch.from_numpy(d[:, feat_dim]).long() - 1\n",
    "elif disc_type == 'Gender':\n",
    "    disc_n = 2\n",
    "    class_labels = torch.from_numpy(d[:, feat_dim+1]).long() - 1\n",
    "### predict label seperately\n",
    "regress_labels = torch.from_numpy(d[:, pred_type_indx-6]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f89ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = np.arange(8000), np.arange(8000,10000)[held_out_idx]\n",
    "np.random.shuffle(train_idx)\n",
    "\n",
    "train_batches = np.array_split(train_idx, len(train_idx) / batch_size)\n",
    "test_features, test_class_labels, test_regress_labels = features[test_idx], class_labels[test_idx], regress_labels[test_idx]\n",
    "alpha_disc = 0.0001\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660e8fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features, class_labels, regress_labels, train_batches, batch_size, alpha_disc):\n",
    "    model = Net(disc_n)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0)\n",
    "    cross_entropy = nn.CrossEntropyLoss()\n",
    "    mse = nn.MSELoss()\n",
    "    ## MAE is\n",
    "    mae = nn.L1Loss()\n",
    "\n",
    "\n",
    "    ## train the network\n",
    "    for epoch in range(15):  # loop over the dataset multiple times\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = g['lr']/10\n",
    "\n",
    "        for i, b in enumerate(train_batches):\n",
    "            batch_features, b_class_labels, b_regress_labels = features[b], class_labels[b], regress_labels[b]\n",
    "\n",
    "            discr, pred = model(batch_features)\n",
    "            discr_loss, pred_loss = cross_entropy(discr, b_class_labels), mse(pred, b_regress_labels)\n",
    "            loss = -discr_loss*alpha_disc + pred_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return model          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aif360",
   "language": "python",
   "name": "aif360"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
